# ğŸŒŒ Orbit: AI-Powered Conversation Intelligence Platform

> Real-time facial recognition, conversation tracking, and intelligent networking for the modern world.

Orbit is a comprehensive AI platform that bridges physical conversations with digital intelligence. It uses computer vision, natural language processing, and web search to automatically identify people in real-time, track conversation topics, and build rich professional profiles.

---

## ğŸ¯ **What Orbit Does**

### **Real-Time Intelligence**
- **ğŸ‘ï¸ Live Facial Recognition**: Identify people in your camera feed instantly
- **ğŸ™ï¸ Conversation Recording**: Automatic audio capture and transcription  
- **ğŸ¤– Topic Extraction**: AI-powered analysis of what you discussed
- **ğŸ’¾ Smart Caching**: Automatic profile building and conversation history

### **Conversation-Driven Networking**
- **ğŸ“ Automatic Logging**: Every person who appears in frame gets logged
- **ğŸ”— Topic Linking**: Conversation topics automatically added to participant profiles
- **ğŸ“Š Rich Profiles**: Professional info, education, achievements, and social media
- **ğŸŒ Web Search Integration**: Automatic research on unknown individuals

---

## ğŸ—ï¸ **Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚    Backend      â”‚    â”‚   AI Services   â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ React UI      â”‚â—„â”€â”€â–ºâ”‚ â€¢ Face Recognition â”‚â—„â”€â”€â–ºâ”‚ â€¢ Cerebras LLM  â”‚
â”‚ â€¢ Real-time Feedâ”‚    â”‚ â€¢ Audio Recording â”‚    â”‚ â€¢ Face Search   â”‚
â”‚ â€¢ Profile Views â”‚    â”‚ â€¢ Web Search      â”‚    â”‚ â€¢ Web Scraping  â”‚
â”‚ â€¢ Conversation  â”‚    â”‚ â€¢ Cache System    â”‚    â”‚ â€¢ Topic Analysisâ”‚
â”‚   Management    â”‚    â”‚ â€¢ Integration     â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Core Components**

#### **ğŸ–¥ï¸ Frontend (Next.js)**
- **Live Video Feed**: Real-time webcam with face detection overlays
- **Person Profiles**: Rich detailed views with professional info and conversation history
- **Conversation Management**: Track topics and link to participants
- **Network Visualization**: Interactive graph of connections and relationships

#### **âš™ï¸ Backend (Python)**
- **Facial Recognition**: InsightFace + DeepFace for accurate identification
- **Audio Pipeline**: Groq Whisper for transcription + LLM topic extraction
- **Web Intelligence**: Face search + content scraping + AI analysis
- **Cache System**: Persistent storage of profiles and conversation data

#### **ğŸ§  AI Layer**
- **LLM Integration**: Cerebras GPT-OSS-120B for fast, accurate analysis
- **Topic Extraction**: Automatic identification of 3-5 conversation topics
- **Profile Building**: Structured data extraction from web sources
- **Smart Matching**: Confidence scoring and verification

---

## ğŸš€ **Quick Start**

### **Prerequisites**
- Python 3.8+ and Node.js 18+
- Webcam and microphone
- API keys (see setup below)

### **1. Clone and Setup**
```bash
git clone <repository-url>
cd Orbit

# Backend setup
cd backend
pip install -r requirements.txt
cp env.example .env
# Edit .env with your API keys

# Frontend setup  
cd ../frontend
npm install
```

### **2. Configure API Keys**
Edit `backend/.env`:
```env
# Required for facial recognition
FACECHECK_API_TOKEN=your_token

# Required for web search  
SERPAPI_KEY=your_key

# Required for AI analysis
CEREBRAS_KEY=your_key

# Optional for audio transcription
GROQ_API_KEY=your_key
```

### **3. Start the System**
```bash
# Terminal 1: Backend
cd backend
python server.py

# Terminal 2: Frontend  
cd frontend
npm run dev
```

### **4. Access the Application**
- Frontend: http://localhost:3000
- Backend API: http://localhost:8000

---

## ğŸ¬ **How It Works**

### **The Conversation Flow**

1. **ğŸ¥ Start Camera Session**
   ```
   Camera starts â†’ Frame presence tracking begins
   Audio recording starts â†’ Real-time transcription
   ```

2. **ğŸ‘¤ Person Detection**  
   ```
   Face detected â†’ Recognition attempt â†’ Profile lookup
   Unknown person â†’ Web search â†’ Profile creation
   Known person â†’ Load existing profile â†’ Update presence
   ```

3. **ğŸ—£ï¸ Conversation Capture**
   ```
   Audio captured â†’ Groq Whisper transcription
   Text analyzed â†’ LLM topic extraction (3-5 topics)
   ```

4. **ğŸ”— Automatic Integration**
   ```
   Session ends â†’ Find all participants in frame
   Extract topics â†’ Update each participant's cache
   Link conversation data â†’ Build conversation history
   ```

### **Example Workflow**

```
ğŸ“¹ Camera Session: "Discussion about AI and startups"

ğŸ‘¥ Participants Detected:
   â€¢ John Smith (recognized from cache)
   â€¢ Jane Doe (unknown â†’ web search â†’ profile created)

ğŸ™ï¸ Audio Transcribed:
   "We talked about the future of AI startups and funding trends..."

ğŸ¤– Topics Extracted:
   â€¢ AI Startups
   â€¢ Funding Trends  
   â€¢ Future Technology

ğŸ’¾ Cache Updated:
   â€¢ John Smith's profile â† conversation topics added
   â€¢ Jane Doe's profile â† conversation topics added
```

---

## ğŸ“ **Project Structure**

```
Orbit/
â”œâ”€â”€ backend/                    # Python backend services
â”‚   â”œâ”€â”€ facial_recognition/     # Face detection & recognition
â”‚   â”œâ”€â”€ recording/             # Audio capture & transcription  
â”‚   â”œâ”€â”€ search/                # Web search & content scraping
â”‚   â”œâ”€â”€ llm/                   # AI analysis & topic extraction
â”‚   â”œâ”€â”€ cache/                 # Person profiles & images
â”‚   â”œâ”€â”€ logs/                  # Session & integration logs
â”‚   â”œâ”€â”€ conversation_integration.py # Core integration logic
â”‚   â””â”€â”€ server.py              # FastAPI backend server
â”‚
â”œâ”€â”€ frontend/                  # Next.js React frontend
â”‚   â”œâ”€â”€ src/components/        # UI components
â”‚   â”‚   â”œâ”€â”€ main/             # Camera feed & detection
â”‚   â”‚   â”œâ”€â”€ profile/          # Person profiles & details
â”‚   â”‚   â””â”€â”€ layout/           # Navigation & layout
â”‚   â”œâ”€â”€ src/data/             # Data adapters & utilities
â”‚   â””â”€â”€ src/utils/            # Helper functions
â”‚
â””â”€â”€ README.md                  # This file
```

---

## ğŸ›ï¸ **Key Features**

### **ğŸ” Advanced Recognition**
- **Multi-Modal Matching**: Face vectors + photo comparison + DeepFace verification
- **Confidence Scoring**: Multiple similarity metrics for accurate identification  
- **Unknown Person Handling**: Automatic web search and profile creation
- **Cache Learning**: System improves recognition over time

### **ğŸ™ï¸ Intelligent Audio**
- **Real-Time Transcription**: Groq Whisper Large Turbo for accuracy
- **Topic Extraction**: LLM analysis of conversation content
- **Multi-Language Support**: Automatic language detection
- **Conversation Linking**: Topics automatically linked to all participants

### **ğŸŒ Web Intelligence**
- **Face Search**: FaceCheck.id integration for photo matching
- **Content Scraping**: Comprehensive web data extraction
- **Profile Building**: Structured data with professional info, education, achievements
- **Source Verification**: Quality scoring and credibility indicators

### **ğŸ’¾ Smart Caching**
- **Persistent Profiles**: Rich JSON profiles with conversation history
- **Incremental Updates**: Profiles grow with each conversation
- **Frame Presence Tracking**: Detailed logs of who appeared when
- **Integration Logs**: Complete audit trail of all processing

---

## ğŸ› ï¸ **Configuration**

### **Recognition Settings**
```python
# In facial_recognition/webcam_recognition.py
recognition_threshold = 0.7        # Face matching confidence
track_timeout = 1.5               # Seconds before "left" event
unknown_person_timeout = 5.0      # Delay before unknown person search
```

### **Audio Settings**  
```python
# In recording/transcriber.py
model = "whisper-large-v3-turbo"  # Transcription model
auto_summarize = True             # Enable topic extraction
temperature = 0.3                 # LLM creativity setting
```

### **Search Settings**
```python
# In search/modules/
min_score = 85                    # Face search confidence threshold
max_face_results = 3              # Number of face matches to process
max_serp_per_url = 2             # Web search results per URL
```

---

## ğŸ“Š **Data Flow**

### **Cache File Structure**
```json
{
  "person_analysis": {
    "personal_info": {
      "full_name": "John Smith",
      "location": "San Francisco, CA",
      "interests": ["AI", "Technology"]
    },
    "professional_info": {
      "current_position": "Senior Engineer",
      "company": "TechCorp",
      "previous_positions": [...]
    },
    "conversation_history": [
      {
        "date": "2025-09-14T03:55:47",
        "topics": ["AI Startups", "Funding", "Technology"],
        "duration": 120,
        "presence_time": 95
      }
    ]
  }
}
```

### **Session Logs**
```json
{
  "session_metadata": {
    "session_id": "20250914_035534",
    "total_unique_participants": 2,
    "duration_seconds": 120
  },
  "participants_summary": {
    "1": {
      "name": "John Smith",
      "recognition_status": "recognized",
      "total_presence_time": 95.2
    }
  }
}
```

---

## ğŸ”§ **Development**

### **Adding New Features**
1. **Backend**: Add endpoints in `server.py`, implement logic in modules
2. **Frontend**: Create components in `src/components/`, add routes in `app/`
3. **Integration**: Update `conversation_integration.py` for new data flows

### **Testing**
```bash
# Backend tests
cd backend
python -m pytest

# Frontend tests  
cd frontend
npm test

# Integration testing
python conversation_integration.py
```

### **API Documentation**
- Backend API docs: http://localhost:8000/docs (FastAPI auto-generated)
- Key endpoints: `/webcam/start`, `/webcam/stop`, `/cache/list`, `/voice/summarize`

---

## ğŸš¨ **Troubleshooting**

| Issue | Solution |
|-------|----------|
| Camera not detected | Check permissions, try different camera index |
| Face recognition failing | Verify lighting, face angle, update recognition threshold |
| Audio not recording | Check microphone permissions, verify audio device |
| LLM errors | Verify API keys, check rate limits |
| Frontend not loading | Ensure backend is running, check CORS settings |

---

## ğŸ¯ **Use Cases**

### **Professional Networking**
- **Conferences & Events**: Automatically track who you meet and what you discuss
- **Business Meetings**: Build conversation history with clients and partners  
- **Networking Events**: Never forget a name or conversation topic again

### **Personal Memory**
- **Social Gatherings**: Remember conversations with friends and family
- **Learning Sessions**: Track discussion topics in study groups or workshops
- **Community Building**: Build rich profiles of community members

### **Research & Analysis**
- **Interview Studies**: Systematic tracking of research conversations
- **Market Research**: Capture insights from customer conversations
- **Content Creation**: Track topics and sources for content development

---

## ğŸ¤ **Contributing**

We welcome contributions! Please see our contributing guidelines:

1. Fork the repository
2. Create a feature branch
3. Make your changes with tests
4. Submit a pull request

Key areas for contribution:
- New recognition algorithms
- Additional LLM providers  
- Frontend UI improvements
- Mobile app development
- Integration with CRM systems

---

## ğŸ“„ **License**

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ™ **Acknowledgments**

- **InsightFace**: Face recognition models
- **Groq**: Fast audio transcription
- **Cerebras**: Ultra-fast LLM inference
- **FaceCheck.id**: Face search capabilities
- **Next.js & React**: Frontend framework
- **FastAPI**: Backend API framework

---

**ğŸŒŒ Orbit: Where conversations become intelligence.**

*Built with â¤ï¸ for the future of human connection.*
